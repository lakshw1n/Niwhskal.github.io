<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://niwhskal.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://niwhskal.github.io/" rel="alternate" type="text/html" /><updated>2021-06-05T17:04:49+05:30</updated><id>https://niwhskal.github.io/feed.xml</id><title type="html">Lakshwin Shreesha</title><subtitle>Lakshwin Shreesha's blog</subtitle><author><name>Lakshwin Shreesha</name></author><entry><title type="html">Computability of Life</title><link href="https://niwhskal.github.io/Computability-Of-Life/" rel="alternate" type="text/html" title="Computability of Life" /><published>2021-06-05T00:00:00+05:30</published><updated>2021-06-05T00:00:00+05:30</updated><id>https://niwhskal.github.io/Computability-Of-Life</id><content type="html" xml:base="https://niwhskal.github.io/Computability-Of-Life/">&lt;p&gt;When Alan Turing laid the principles of computing, he presupposed that it’s capabilities be limitless. A machine which could carry out any computation no matter the complexity— Turing complete was what he called it.&lt;/p&gt;

&lt;p&gt;Rightly so, now, in 2021, we have the modern computer which embodies his vision — an incredibly powerful, Turing complete machine. With advances in every possible area being enabled by computers, the possibilities with a modern computer seem endless. Furthermore, with recent advances in deep learning, computing machines seem to even hold the promise of intelligent behavior — the kind you’d find in all living organisms. There’s a lot of hype with people trying to play god with computers. But as dramatic and groundbreaking as it sounds, this is an illusion. Any mechanistic human-made von-neumann based computation device will be incapable of replicating any attribute of living organisms. Nature is a much more complicated entity. Our whole foundation of logic is a mere artifact in nature.&lt;/p&gt;

&lt;p&gt;A question that drove this belief of mine, involves a comparison between biological organisms and the modern computer (say an imac). Are biological organisms Turing complete? Can they solve any well-defined problem (within their biological limits of course)? More importantly, do they always produce the same behavior to a particular input stimulus ?&lt;/p&gt;

&lt;p&gt;Of course not. Nature is inherently abstract. Nothing is well-defined. It’s Turing-incomplete. But for the sake of an interesting argument, let’s assume that it is Turing-complete. This puts it in the same realm of that of a computer, wherein their behavior would be according to the formal, well-defined language of Mathematics. Because mathematics leaves no room for ambiguity, biological organisms must produce the exact same behavior each time a mathematically definable stimulus is input. Exactly like that of an imac. But, a problem persists here. Way back in 1930, Kurt Godel, a logician, proved that any system described unambiguously by a language such as mathematics can not be both consistent as well as complete &lt;a class=&quot;citation&quot; href=&quot;#godel-1&quot;&gt;(Godel, 1931)&lt;/a&gt;&lt;a class=&quot;citation&quot; href=&quot;#godel-2&quot;&gt;(Godel, 1932)&lt;/a&gt;. He showed that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There are true statements about a system which cannot be proved to be true 
(in-completeness) and that,&lt;/li&gt;
  &lt;li&gt;There are some statements which are both true and false. (In-consistent)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For our case, this means that certain behaviors/processes of biological organisms can never be mathematically captured by definite statements of proof. As a consequence, a biological organism can never be completely described by a formal language such as mathematics. And because of this, it would be impossible to craft an algorithm that replicates the biological organism on your computer. Nature is Turing in-complete.&lt;/p&gt;

&lt;p&gt;Godel’s arguments seem to hold in the biologically-inspired, Deep Learning domain as well. Artificial Neural networks mimic the chaotic interconnections of biological neurons, but resort to statistics and optimization in order to work well. There seems to be some entity of biological neurons that is incapable of being represented by the mathematical foundations that ANN’s rely on. Despite it’s promise, DL has been an ad-hoc technique to make software do more. A far-cry from it’s predicted potential.&lt;/p&gt;

&lt;p&gt;The thing is Biological organisms are on a different architecture altogether. Evolution drove life towards one thing, survival. Everything else, mobility, cognition, intelligence etc., have been unintended artifacts. It’s funny. What we desperately value is simply a n-th order artifact in nature. The web of complexity in even the most basic of life forms, prokaryotes, is mindshatteringly complex. Considering the number of variables involved, there’s no way evolution was brute force. What then caused the genesis of prokaryotes?&lt;/p&gt;

&lt;p&gt;Nature must have been constructed solely based on “intuition” towards survival. Take cognition for example, most of what we interpret as cognitive abilities can only be described or interpreted through behavior. It’s impossible to formally, sufficiently and unambiguously describe what it means to think, understand, feel, or be intelligent. We’re all beings of intuition. Even though the formality and rigor of logic is robust, it’s intuition that is abundant in nature. The reason as to why reality prefers intuition is perhaps because intuition offers multiple interpretations about a stressor, enabling myriad solutions to alleviate the source of struggle. This would obviously not be possible for any logically structured entity.&lt;/p&gt;

&lt;p&gt;Behind every discovery, there has been an idea born out of intuition. It’s what Godel relied on to pen down his logical theory of incompleteness and it’s what humanity will use to understand life. It’s funny that I’m involved in studying something that I cannot formally describe.&lt;/p&gt;

&lt;p&gt;Mathematics is a language for us to formalize our intuition. But despite it’s capabilities, it will be a lossy interpretation of intuition. Perhaps a new channel for us to capture intuition with mathematics is required.&lt;/p&gt;

&lt;p&gt;Biological organisms are special. Reverse-engineering them is hard because evolution obscures history. There is no version control. It’s simply what there is at present. In the face of such intractability, success may lie in studying organisms which have the least amount of evolutionary “interference”. The Prokaryotes. The very first set of living organisms we know of.&lt;/p&gt;

&lt;p&gt;The field of Basal cognition &lt;a class=&quot;citation&quot; href=&quot;#Reframing-cognition&quot;&gt;(Lyon et al., 2021)&lt;/a&gt; concerns itself with the study of cognition in basic life forms.  The future, when viewed through the lens of Basal cognition may resolve the issue of whether life is computational. And if not, it can atleast explain to what degree life can be algorithmically expressed. Until then, we go about our business and try as hard as possible to not cringe and die ten times over when someone brings up the unholy abbreviated term of the words: “Artificial Intelligence”.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;godel-1&quot;&gt;Godel, K. (1931). Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme I. &lt;i&gt;Monatshefte Für Mathematik Und Physik&lt;/i&gt;, &lt;i&gt;38&lt;/i&gt;. https://doi.org/10.1007/BF01700692&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;godel-2&quot;&gt;Godel, K. (1932). Über Vollständigkeit und Widerspruchsfreiheit. &lt;i&gt;Ergebnisse Eines Mathematischen Kolloquiums&lt;/i&gt;, &lt;i&gt;3&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Reframing-cognition&quot;&gt;Lyon, P., Keijzer, F., Arendt, D., &amp;amp; Levin, M. (2021). Reframing cognition: getting down to biological basics. &lt;i&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/i&gt;, &lt;i&gt;376&lt;/i&gt;(1820). https://doi.org/10.1098/rstb.2019.0750&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Lakshwin Shreesha</name></author><summary type="html">When Alan Turing laid the principles of computing, he presupposed that it’s capabilities be limitless. A machine which could carry out any computation no matter the complexity— Turing complete was what he called it.</summary></entry><entry><title type="html">Towards Extreme Generalization</title><link href="https://niwhskal.github.io/Towards-Extreme_Generalization/" rel="alternate" type="text/html" title="Towards Extreme Generalization" /><published>2021-04-04T00:00:00+05:30</published><updated>2021-04-04T00:00:00+05:30</updated><id>https://niwhskal.github.io/Towards-Extreme_Generalization</id><content type="html" xml:base="https://niwhskal.github.io/Towards-Extreme_Generalization/">&lt;p&gt;In 2019, François Chollet provided one of the most comprehensive definitions of intelligence to date. He described the trait as that which enables wild generalization across tasks, optimized specifically for flexibility and adaptability. &lt;a class=&quot;citation&quot; href=&quot;#fchol&quot;&gt;(Chollet, 2019)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately trends in ML research today are a far cry from his description, leveraging unlimited priors to showcase superior performance at specific tasks, depicting the intelligence of the person involved in creating it rather than that of the algorithm. All of the SOTA in ML research today showcases the crystallized output of intelligence but not the process of intelligence itself.&lt;/p&gt;

&lt;p&gt;This brings us to the question of what the way forward is? Are neural networks the key to superior generalization or do we need a new framework altogether?&lt;/p&gt;

&lt;p&gt;In my opinion, neural networks, atleast in the framework of: Training, Back-Prop, and Optimization are quite useless to achieve the state of superior generalization.&lt;/p&gt;

&lt;p&gt;An agent which serves to generalize across multiple tasks needs to have a sense of uncertainty about it’s priors. It must have the ability to decrease/increase that uncertainty on it’s own (by a process which is independent of data). In order to escape from the bubble that unlimited training data provides, an agent needs to cut off it’s reliance with data. Biological organisms seeem to do fine in this regard, so why can’t ML agents?&lt;/p&gt;

&lt;p&gt;The brain is a master of dealing with uncertainty. If we draw a superficial comparison with neural networks and the brain, you can see that they’re both connected roughly the same. The complexity of their connections obscure both their dynamics (&lt;a class=&quot;citation&quot; href=&quot;#dyn1&quot;&gt;(Cessac B, 2007)&lt;/a&gt;,&lt;a class=&quot;citation&quot; href=&quot;#dyn2&quot;&gt;(Tian, 2017)&lt;/a&gt;,&lt;a class=&quot;citation&quot; href=&quot;#dyn3&quot;&gt;(Jacot et al., 2020)&lt;/a&gt;,&lt;a class=&quot;citation&quot; href=&quot;#dyn4&quot;&gt;(Tachet et al., 2020)&lt;/a&gt;,&lt;a class=&quot;citation&quot; href=&quot;#dyn5&quot;&gt;(Kunin et al., 2021)&lt;/a&gt; have made some progress though). we don’t know how an input gets transformed as it passes through several layers.&lt;/p&gt;

&lt;p&gt;There are signifcant differences though. The brain doesn’t work on back propagation &lt;a class=&quot;citation&quot; href=&quot;#bp1&quot;&gt;(Roelfsema &amp;amp; Holtmaat, 2018)&lt;/a&gt;, &lt;a class=&quot;citation&quot; href=&quot;#bp2&quot;&gt;(Whittington &amp;amp; Bogacz, 2019)&lt;/a&gt; and has a control over it’s experiences. It can assign relevance/determine validity because everything is uncertain, it is too fluid of an entity. Neural networks share the property of intractability with the brain, but they are forced to behave in a pre-determined way by the means of labels. Hard-coded labels enforce unknown constraints on the network, forcing networks to learn shortcut tricks (textures, patterns, colors etc.). If a network is trained solely to detect pictures of faces, it’s behavior is morphed so as to “see” faces, whether it be in patterns, shortcut hacks or some other feature. So when the network makes a mistake, it technically isn’t a mistake from the perspective of the neural network, but a mismatch in perspective between what is true and what isn’t. And this has to do with assigning labels. We need to rethink the way a neural network leans. A more flexible approach is required. One which adapts constantly based on new data or ingrained priors(designed before training). Pre-defined datasets and hard-coded labels are the death of generalization.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;fchol&quot;&gt;Chollet, F. (2019). &lt;i&gt;On the Measure of Intelligence&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;dyn1&quot;&gt;Cessac B, S. M. (2007). From neuron to neural network dynamics. In &lt;i&gt;Eur. Phys. J. Spec. Top 142&lt;/i&gt; (pp. 7–88).&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;dyn2&quot;&gt;Tian, Y. (2017). &lt;i&gt;An Analytical Formula of Population Gradient for two-layered ReLU network and its Applications in Convergence and Critical Point Analysis&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;dyn3&quot;&gt;Jacot, A., Gabriel, F., &amp;amp; Hongler, C. (2020). &lt;i&gt;Neural Tangent Kernel: Convergence and Generalization in Neural Networks&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;dyn4&quot;&gt;Tachet, R., Pezeshki, M., Shabanian, S., Courville, A., &amp;amp; Bengio, Y. (2020). &lt;i&gt;On the Learning Dynamics of Deep Neural Networks&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;dyn5&quot;&gt;Kunin, D., Sagastuy-Brena, J., Ganguli, S., Yamins, D. L. K., &amp;amp; Tanaka, H. (2021). &lt;i&gt;Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;bp1&quot;&gt;Roelfsema, P., &amp;amp; Holtmaat, A. (2018). Control of synaptic plasticity in deep cortical networks. &lt;i&gt;Nature Reviews Neuroscience&lt;/i&gt;, &lt;i&gt;19&lt;/i&gt;, 166–180. https://doi.org/10.1038/nrn.2018.6&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;bp2&quot;&gt;Whittington, J., &amp;amp; Bogacz, R. (2019). Theories of Error Back-Propagation in the Brain. &lt;i&gt;Trends in Cognitive Sciences&lt;/i&gt;, &lt;i&gt;23&lt;/i&gt;. https://doi.org/10.1016/j.tics.2018.12.005&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Lakshwin Shreesha</name></author><summary type="html">In 2019, François Chollet provided one of the most comprehensive definitions of intelligence to date. He described the trait as that which enables wild generalization across tasks, optimized specifically for flexibility and adaptability. (Chollet, 2019)</summary></entry></feed>